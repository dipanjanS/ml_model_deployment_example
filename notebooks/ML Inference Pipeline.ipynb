{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Basic Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version 1.1.3\n",
      "Numpy version 1.19.2\n",
      "Scikit Learn version 0.23.2\n",
      "XGBoost version 1.4.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import xgboost as xgb\n",
    "\n",
    "print('Pandas version', pd.__version__)\n",
    "print('Numpy version', np.__version__)\n",
    "print('Scikit Learn version', sklearn.__version__)\n",
    "print('XGBoost version', xgb.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/census.csv')\n",
    "final_columns = set(df.columns) - set(['fnlwgt'])\n",
    "final_columns = list(final_columns)\n",
    "df = df[final_columns]\n",
    "df = df.drop(columns=['income'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Sample Request Datasets\n",
    "\n",
    "Here we emulate how data would look when we build an API to serve model requests\n",
    "\n",
    "Typically requests and responses are generated in JSON, hence we will work with python dictionaries as inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'education': 'Assoc-voc',\n",
       " 'workclass': 'Private',\n",
       " 'native.country': 'United-States',\n",
       " 'sex': 'Male',\n",
       " 'education.num': 11,\n",
       " 'race': 'White',\n",
       " 'occupation': 'Craft-repair',\n",
       " 'capital.gain': 0,\n",
       " 'capital.loss': 2603,\n",
       " 'marital.status': 'Married-civ-spouse',\n",
       " 'relationship': 'Husband',\n",
       " 'hours.per.week': 40,\n",
       " 'age': 21}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request_data1 = df.iloc[25].to_dict()\n",
    "request_data1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating another sample request dataset with multiple records and introducing more missing data and fields to simulate real-world scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'education': 'HS-grad',\n",
       "  'workclass': '?',\n",
       "  'occupation': '?',\n",
       "  'capital.gain': 0,\n",
       "  'capital.loss': 4356,\n",
       "  'hours.per.week': 40},\n",
       " {'education': 'HS-grad',\n",
       "  'workclass': 'Private',\n",
       "  'native.country': 'United-States',\n",
       "  'sex': 'Female',\n",
       "  'education.num': 9,\n",
       "  'race': 'White',\n",
       "  'occupation': 'Exec-managerial',\n",
       "  'capital.gain': 0,\n",
       "  'capital.loss': 4356,\n",
       "  'marital.status': 'Widowed',\n",
       "  'relationship': 'Not-in-family',\n",
       "  'hours.per.week': 18,\n",
       "  'age': 82},\n",
       " {'education': 'Some-college',\n",
       "  'workclass': '',\n",
       "  'native.country': 'United-States',\n",
       "  'sex': 'Female',\n",
       "  'education.num': 10,\n",
       "  'race': '?',\n",
       "  'occupation': '?',\n",
       "  'capital.gain': 0,\n",
       "  'capital.loss': 4356,\n",
       "  'marital.status': 'Widowed',\n",
       "  'relationship': 'Unmarried',\n",
       "  'hours.per.week': '?',\n",
       "  'age': 66}]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request_data2 = df.iloc[0:3].to_dict(orient='records')\n",
    "\n",
    "request_data2[2]['workclass'] = ''\n",
    "request_data2[2]['race'] = '?'\n",
    "request_data2[2]['hours.per.week'] = '?'\n",
    "\n",
    "del request_data2[0]['native.country']\n",
    "del request_data2[0]['sex']\n",
    "del request_data2[0]['age']\n",
    "del request_data2[0]['race']\n",
    "del request_data2[0]['relationship']\n",
    "del request_data2[0]['marital.status']\n",
    "del request_data2[0]['education.num']\n",
    "\n",
    "request_data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Create function to load model artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "\n",
    "\n",
    "def load_model_artifacts(path):\n",
    "    with open(path, \"rb\") as dill_infile:\n",
    "        model_artifacts = dill.load(dill_infile)\n",
    "        \n",
    "    return model_artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['dummy_encoder', 'cat_init_features', 'num_init_features', 'cat_ohe_features', 'cat_imputer', 'num_imputer', 'xgb_model', 'column_names_order'])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML_ARTIFACTS_PATH = \"../ml_app/saved_models/census_xgb_artifacts.pkl\"\n",
    "\n",
    "ml_artifacts = load_model_artifacts(path=ML_ARTIFACTS_PATH)\n",
    "ml_artifacts.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Create function to form a dataset from request data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_dataset(request_data, ml_model_artifacts,\n",
    "                 na_values=['', '?']):\n",
    "    \n",
    "    # convert request records into a list of dicts\n",
    "    request_data = [request_data] if type(request_data) == dict else request_data\n",
    "    # for each record add in missing fields\n",
    "    for record in request_data:\n",
    "        # get list of inital data features\n",
    "        feature_names = list(ml_model_artifacts['cat_init_features']) + list(ml_model_artifacts['num_init_features'])\n",
    "        # get list of features missing in record\n",
    "        features_not_present = list(set(feature_names) - set(record.keys()))\n",
    "        # fill feature names with a missing value placeholder\n",
    "        for feature in features_not_present:\n",
    "            record[feature] = '?'\n",
    "    \n",
    "    # convert list of record dicts into a dataframe     \n",
    "    request_df = pd.DataFrame(request_data)\n",
    "    # convert missing value tokens to NaNs\n",
    "    for token in na_values:\n",
    "        request_df = request_df.replace({token : np.NaN})\n",
    "\n",
    "    return request_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>education</th>\n",
       "      <th>workclass</th>\n",
       "      <th>occupation</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>sex</th>\n",
       "      <th>education.num</th>\n",
       "      <th>race</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>relationship</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HS-grad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Private</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>18.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Female</td>\n",
       "      <td>9.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Some-college</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Female</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      education workclass       occupation  capital.gain  capital.loss  \\\n",
       "0       HS-grad       NaN              NaN             0          4356   \n",
       "1       HS-grad   Private  Exec-managerial             0          4356   \n",
       "2  Some-college       NaN              NaN             0          4356   \n",
       "\n",
       "   hours.per.week native.country     sex  education.num   race marital.status  \\\n",
       "0            40.0            NaN     NaN            NaN    NaN            NaN   \n",
       "1            18.0  United-States  Female            9.0  White        Widowed   \n",
       "2             NaN  United-States  Female           10.0    NaN        Widowed   \n",
       "\n",
       "    relationship   age  \n",
       "0            NaN   NaN  \n",
       "1  Not-in-family  82.0  \n",
       "2      Unmarried  66.0  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request_df = form_dataset(request_data=request_data2,\n",
    "                          ml_model_artifacts=ml_artifacts)\n",
    "request_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Impute and Encode Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_and_encode_features(request_df, ml_model_artifacts):\n",
    "    \n",
    "    # separate categorical and numeric features\n",
    "    categorical_features_init = ml_model_artifacts['cat_init_features']\n",
    "    numeric_features_init = ml_model_artifacts['num_init_features']\n",
    "    request_df_cat = request_df[categorical_features_init]\n",
    "    request_df_num = request_df[numeric_features_init]\n",
    "    \n",
    "    # impute categorical features\n",
    "    categorical_imputer = ml_model_artifacts['cat_imputer']\n",
    "    request_df_cat = pd.DataFrame(categorical_imputer.transform(request_df_cat), \n",
    "                                  columns=categorical_features_init)\n",
    "    \n",
    "    # one-hot encode categorical features (dummy variables)\n",
    "    categorical_ohe = ml_model_artifacts['dummy_encoder']\n",
    "    request_df_cat_ohe = categorical_ohe.transform(request_df_cat).toarray()\n",
    "    \n",
    "    categorical_features_ohe = ml_model_artifacts['cat_ohe_features']\n",
    "    request_df_cat_ohe = pd.DataFrame(request_df_cat_ohe, \n",
    "                                      columns=categorical_features_ohe)\n",
    "    \n",
    "    # impute numeric features\n",
    "    numeric_imputer = ml_model_artifacts['num_imputer']\n",
    "    request_df_num = pd.DataFrame(numeric_imputer.transform(request_df_num), \n",
    "                                  columns=numeric_features_init)\n",
    "    \n",
    "    # combine numeric and categorical features\n",
    "    request_df = pd.concat([request_df_num, request_df_cat_ohe], axis=1)\n",
    "    # align column names for feature set\n",
    "    column_names = ml_model_artifacts['column_names_order']\n",
    "    request_df = request_df[column_names]\n",
    "    \n",
    "    return request_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>education.num</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>relationship_Husband</th>\n",
       "      <th>relationship_Not-in-family</th>\n",
       "      <th>relationship_Other-relative</th>\n",
       "      <th>relationship_Own-child</th>\n",
       "      <th>relationship_Unmarried</th>\n",
       "      <th>...</th>\n",
       "      <th>education_9th</th>\n",
       "      <th>education_Assoc-acdm</th>\n",
       "      <th>education_Assoc-voc</th>\n",
       "      <th>education_Bachelors</th>\n",
       "      <th>education_Doctorate</th>\n",
       "      <th>education_HS-grad</th>\n",
       "      <th>education_Masters</th>\n",
       "      <th>education_Preschool</th>\n",
       "      <th>education_Prof-school</th>\n",
       "      <th>education_Some-college</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57.8</td>\n",
       "      <td>40.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>4356.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4356.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4356.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  hours.per.week  education.num  capital.loss  capital.gain  \\\n",
       "0  57.8            40.0            7.8        4356.0           0.0   \n",
       "1  82.0            18.0            9.0        4356.0           0.0   \n",
       "2  66.0            40.0           10.0        4356.0           0.0   \n",
       "\n",
       "   relationship_Husband  relationship_Not-in-family  \\\n",
       "0                   0.0                         0.0   \n",
       "1                   0.0                         1.0   \n",
       "2                   0.0                         0.0   \n",
       "\n",
       "   relationship_Other-relative  relationship_Own-child  \\\n",
       "0                          0.0                     0.0   \n",
       "1                          0.0                     0.0   \n",
       "2                          0.0                     0.0   \n",
       "\n",
       "   relationship_Unmarried  ...  education_9th  education_Assoc-acdm  \\\n",
       "0                     0.0  ...            0.0                   0.0   \n",
       "1                     0.0  ...            0.0                   0.0   \n",
       "2                     1.0  ...            0.0                   0.0   \n",
       "\n",
       "   education_Assoc-voc  education_Bachelors  education_Doctorate  \\\n",
       "0                  0.0                  0.0                  0.0   \n",
       "1                  0.0                  0.0                  0.0   \n",
       "2                  0.0                  0.0                  0.0   \n",
       "\n",
       "   education_HS-grad  education_Masters  education_Preschool  \\\n",
       "0                1.0                0.0                  0.0   \n",
       "1                1.0                0.0                  0.0   \n",
       "2                0.0                0.0                  0.0   \n",
       "\n",
       "   education_Prof-school  education_Some-college  \n",
       "0                    0.0                     0.0  \n",
       "1                    0.0                     0.0  \n",
       "2                    0.0                     1.0  \n",
       "\n",
       "[3 rows x 106 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request_df = impute_and_encode_features(request_df=request_df, \n",
    "                                        ml_model_artifacts=ml_artifacts)\n",
    "request_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Load and make ML model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_predictions(request_df, ml_model_artifacts):\n",
    "    \n",
    "    # load saved ML model\n",
    "    ml_model = ml_model_artifacts['xgb_model']\n",
    "    \n",
    "    # make model predictions\n",
    "    predictions = ml_model.predict(request_df)\n",
    "    \n",
    "    # return predictions\n",
    "    return {\n",
    "        'predicted_classes' : list(predictions)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'predicted_classes': ['<=50K', '<=50K', '<=50K']}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_model_predictions(request_df=request_df, \n",
    "                       ml_model_artifacts=ml_artifacts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Build ML inference pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_ARTIFACTS_PATH = \"../ml_app/saved_models/census_xgb_artifacts.pkl\"\n",
    "\n",
    "\n",
    "def ml_inference_pipeline(request_data):\n",
    "    \n",
    "    # 1. Load model artifacts\n",
    "    ml_artifacts = load_model_artifacts(path=ML_ARTIFACTS_PATH)\n",
    "    \n",
    "    # 2. Create request dataset\n",
    "    request_df = form_dataset(request_data=request_data,\n",
    "                              ml_model_artifacts=ml_artifacts)\n",
    "    \n",
    "    # 3. Impute and Encode Features\n",
    "    request_df = impute_and_encode_features(request_df=request_df, \n",
    "                                            ml_model_artifacts=ml_artifacts)\n",
    "    \n",
    "    # 4. Load and make ML model predictions\n",
    "    pred_response = make_model_predictions(request_df=request_df, \n",
    "                                           ml_model_artifacts=ml_artifacts)\n",
    "    \n",
    "    # return response\n",
    "    return pred_response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test inference pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predicted_classes': ['<=50K']}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_inference_pipeline(request_data=request_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'predicted_classes': ['<=50K', '<=50K', '<=50K']}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_inference_pipeline(request_data=request_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv('../datasets/census.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_data3 = df.iloc[20000:20010].to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'predicted_classes': ['<=50K',\n",
       "  '>50K',\n",
       "  '<=50K',\n",
       "  '<=50K',\n",
       "  '>50K',\n",
       "  '>50K',\n",
       "  '<=50K',\n",
       "  '<=50K',\n",
       "  '<=50K',\n",
       "  '<=50K']}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_inference_pipeline(request_data=request_data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<=50K',\n",
       " '>50K',\n",
       " '<=50K',\n",
       " '<=50K',\n",
       " '>50K',\n",
       " '>50K',\n",
       " '<=50K',\n",
       " '<=50K',\n",
       " '<=50K',\n",
       " '<=50K']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.iloc[20000:20010]['income'].tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
